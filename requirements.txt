# LLM Document Processing System - Production Requirements (HackRX Ready)
# Optimized for webhook deployment with your existing dependencies

# ===========================================
# CORE API FRAMEWORK
# ===========================================
fastapi>=0.100.0
uvicorn[standard]>=0.20.0
pydantic>=2.0.0
python-multipart>=0.0.6

# ===========================================
# DOCUMENT PROCESSING (Your Current Stack)
# ===========================================
PyMuPDF>=1.23.0        # PDF processing
python-docx>=0.8.11    # DOCX processing  
pdfplumber>=0.10.0     # Alternative PDF processing

# ===========================================
# ML/NLP LIBRARIES (Your Current Stack)
# ===========================================
torch>=2.0.0
sentence-transformers>=2.6.1
transformers>=4.40.0
numpy>=1.24.0
scikit-learn>=1.3.0

# ===========================================
# VECTOR DATABASE (Your Current Stack)
# ===========================================
chromadb>=0.4.0
faiss-cpu>=1.7.4

# ===========================================
# LLM INTEGRATION (Your Current + Ollama)
# ===========================================
# Your existing LLM integrations
openai>=1.10.0         # Keep for fallback
anthropic>=0.15.0      # Keep for fallback
langchain>=0.1.0       # Keep if used
langchain-community>=0.0.20

# Ollama integration (primary)
requests>=2.31.0       # For Ollama HTTP API
httpx>=0.25.0          # Async HTTP client

# ===========================================
# TEXT PROCESSING (Your Current Stack)  
# ===========================================
regex>=2023.0.0
spacy>=3.7.0
nltk>=3.8.1

# ===========================================
# CONFIGURATION & ENVIRONMENT (Your Current)
# ===========================================
pyyaml>=6.0
python-dotenv>=1.0.0
configparser>=5.3.0

# ===========================================
# DATABASE & STORAGE (Your Current)
# ===========================================
sqlalchemy>=2.0.0

# ===========================================
# DATA PROCESSING (Your Current)
# ===========================================
pandas>=2.0.0
openpyxl>=3.1.0
xlrd>=2.0.1

# ===========================================
# LOGGING & MONITORING (Your Current + Enhanced)
# ===========================================
loguru>=0.7.0          # Your current logger
prometheus-client>=0.17.0
structlog>=23.0.0

# ===========================================
# HTTP & API CLIENTS (Your Current)
# ===========================================
aiohttp>=3.8.0

# ===========================================
# UTILITIES (Your Current)
# ===========================================
tqdm>=4.65.0
rich>=13.0.0
click>=8.1.0

# ===========================================
# ADDITIONAL PRODUCTION REQUIREMENTS
# ===========================================
# JSON processing (for robust LLM response parsing)
json5>=0.9.14          # Robust JSON parsing
dataclasses-json>=0.6.1  # Dataclass serialization

# Type hints
typing-extensions>=4.8.0

# Production server
gunicorn>=21.2.0       # Production WSGI server

# ===========================================
# TESTING (Your Current Stack)
# ===========================================
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-mock>=3.11.0

# ===========================================
# DEVELOPMENT TOOLS (Your Current Stack)
# ===========================================
black>=23.0.0
isort>=5.12.0
flake8>=6.0.0
mypy>=1.5.0

# ===========================================
# CLOUD DEPLOYMENT OPTIMIZATIONS
# ===========================================
# Caching for performance
cachetools>=5.3.2

# Static file serving
whitenoise>=6.6.0

# Environment variable parsing
python-decouple>=3.8   # Alternative to python-dotenv for production

# ===========================================
# OPTIONAL: EXTERNAL LLM FALLBACKS
# ===========================================
# Uncomment these for additional fallback options:
# together>=0.2.7       # Together API
# groq>=0.4.1           # Groq API (very fast inference)

# ===========================================
# OPTIONAL: GPU SUPPORT (Your Current)  
# ===========================================
# Uncomment if deploying on GPU-enabled infrastructure:
# torch-audio>=2.0.0
# torch-vision>=0.15.0

# ===========================================
# OPTIONAL: DEVELOPMENT ENVIRONMENT
# ===========================================
# Uncomment for development/testing:
# jupyter>=1.0.0
# notebook>=6.5.0
# ipywidgets>=8.0.0

# ===========================================
# VERSION PINNING FOR STABILITY
# ===========================================
# Key packages pinned for webhook deployment stability:
fastapi==0.104.1
uvicorn==0.24.0
pydantic==2.5.0
requests==2.31.0
loguru==0.7.2

# ===========================================
# DEPLOYMENT NOTES
# ===========================================
# 1. This requirements.txt includes all your existing dependencies
# 2. Added Ollama HTTP integration via requests/httpx
# 3. Kept your OpenAI/Anthropic dependencies for fallbacks
# 4. Added production optimizations (gunicorn, caching, etc.)
# 5. Version-pinned critical packages for deployment stability
# 6. Compatible with Railway, Render, Fly.io, and other cloud platforms